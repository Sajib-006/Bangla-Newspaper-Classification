{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w1tzj3KJ_p-"
      },
      "source": [
        "Connect to drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b6PLLbiJQRO",
        "outputId": "47eeb61d-9c79-4b8e-fa25-91b58860730a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /root/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/root/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvtWS5k6Jf7l",
        "outputId": "da8c4a93-be3c-4f1d-bb5e-048b292fbadc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/root/gdrive/MyDrive/Bangla Newspaper Classification\n"
          ]
        }
      ],
      "source": [
        "%cd /root/gdrive/MyDrive/Bangla Newspaper Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgwZ6OwIUFKn"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOe6R7zdUAE3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVyC6X1yKHdQ"
      },
      "source": [
        "Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBFFKrQCJlbd",
        "outputId": "9b514dcd-d134-4ecb-c786-6e6268febd1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'author': 'গাজীপুর প্রতিনিধি', 'category': 'bangladesh', 'category_bn': 'বাংলাদেশ', 'published_date': '০৪ জুলাই ২০১৩, ২৩:২৬', 'modification_date': '০৪ জুলাই ২০১৩, ২৩:২৭', 'tag': ['গাজীপুর'], 'comment_count': 0, 'title': 'কালিয়াকৈরে টিফিন খেয়ে ৫০০ শ্রমিক অসুস্থ, বিক্ষোভ', 'url': 'http://www.prothom-alo.com/bangladesh/article/19030', 'content': 'গাজীপুরের কালিয়াকৈর উপজেলার তেলিরচালা এলাকায় আজ বৃহস্পতিবার রাতের টিফিন খেয়ে একটি পোশাক কারখানার ৫০০ শ্রমিক অসুস্থ হয়ে পড়েছেন। এ ঘটনায় বিক্ষোভ করেছেন ওই কারখানার শ্রমিকেরা।সফিপুর মডার্ন হাসপাতালের জরুরি বিভাগের চিকিত্সক আল আমিন প্রথম আলো ডটকমকে বলেন, খাদ্যে বিষক্রিয়ায় তাঁরা (শ্রমিকেরা) অসুস্থ হয়ে পড়েছেন। এতে আতঙ্কিত হওয়ার কিছু নেই। অসুস্থদের চিকিত্সা দেওয়া হয়েছে।কারখানার শ্রমিক ও পুলিশ সূত্রে জানা যায়, উপজেলার তেলিরচালা এলাকার সেজাদ সোয়েটার লিমিটেড কারখানার শ্রমিকদের আজ রাত সাড়ে সাতটার দিকে টিফিন দেওয়া হয়। টিফিনে ছিল ডিম, রুটি, পেটিস ও কলা। টিফিন খেয়ে শ্রমিকেরা যথারীতি কাজে যোগ দেন। ওই টিফিন খাওয়ার প্রায় এক ঘণ্টা পর রাত সাড়ে আটটার দিকে কয়েকজন শ্রমিকের বমি ও পেট ব্যথা শুরু হয়। এরপর ধীরে ধীরে পুরো কারখানার শ্রমিকেরা অসুস্থ হতে থাকে। অনেকেই কারখানার মেঝেতে ঢলে পড়ে। এতে পাঁচ শতাধিক শ্রমিক অসুস্থ হয়ে পড়ে।পরে কারখানা কর্তৃপক্ষ দ্রুত যানবাহনের ব্যবস্থা করে তাদের সফিপুর জেনারেল হাসপাতাল, সফিপুর মডার্ন হাসপাতাল, উপজেলা স্বাস্থ্য কমপ্লেক্সসহ বিভিন্ন ক্লিনিকে ভর্তি করে। বাসি পচা খাবার দেওয়ায় শ্রমিকরা ক্ষুব্ধ হয়ে কারখানার সামনে বিক্ষোভ করে। খবর পেয়ে পুলিশ গিয়ে শ্রমিকদের বুঝিয়ে ও খাবার সরবরাহ প্রতিষ্ঠানের বিরুদ্ধে ব্যবস্থা নেওয়ার আশ্বাস দিলে শ্রমিকেরা শান্ত হয়।সফিপুর জেনারেল হাসপাতালে ভর্তি শ্রমিক জাকির হোসেন ও আসমা আক্তার বলেন, টিফিন খাওয়ার সময় ডিম ও কেক থেকে দুর্গন্ধ বের হচ্ছিল। এ কারণে অনেকেই ওই খাবার খায়নি। তবে বেশির ভাগ শ্রমিকই ওই খাবার খেয়েছে।কারখানার সহকারী উত্পাদন কর্মকর্তা (এপিএম) বছির উদ্দিন বলেন, টিফিনগুলি যে ঠিকাদারি প্রতিষ্ঠান কারখানায় সরবরাহ করে তাদের বিরুদ্ধে ব্যবস্থা নেওয়া হবে।মৌচাক পুলিশ ফাঁড়ির উপ-পরিদর্শক (এসআই) সৈয়দ আজহারুল ইসলাম প্রথম আলো ডটকমকে বলেন, শ্রমিকদের বুঝিয়ে শান্ত করা হয়েছে। এ ছাড়া কারখানা কর্তৃপক্ষকে খাদ্য সরবরাহ প্রতিষ্ঠানের বিরুদ্ধে ব্যবস্থা নিতে বলা হয়েছে।'}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "with open('data/data.json', encoding='utf-8') as fh:\n",
        "    data = json.load(fh)\n",
        "print(data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BnwMArVJT7L"
      },
      "source": [
        "Trim data for test run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teqRXy6sJTRo"
      },
      "outputs": [],
      "source": [
        "data = data[:50000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1M1FGvdRcHd"
      },
      "source": [
        "Visualize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf2Rj6GsRJRb",
        "outputId": "0ed8c594-8067-4436-fd74-a1c6930b6177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Rows: 80000\n",
            "Total Cols: 10\n"
          ]
        }
      ],
      "source": [
        "print(\"Total Rows:\", len(data))\n",
        "print(\"Total Cols:\", len(data[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ams1_bKM3oP"
      },
      "source": [
        "Show all category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7vIW5DyRh7C",
        "outputId": "9d198ba1-4d8c-41b7-ac35-b7bafba464b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "All columns:\n",
            "author\n",
            "category\n",
            "category_bn\n",
            "published_date\n",
            "modification_date\n",
            "tag\n",
            "comment_count\n",
            "title\n",
            "url\n",
            "content\n"
          ]
        }
      ],
      "source": [
        "print(type(data))\n",
        "print(\"All columns:\")\n",
        "for col in data[0]:\n",
        "  print(col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZ0zyOoagDZL"
      },
      "source": [
        "Retrieve all categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBtpDjXVJ2QS",
        "outputId": "76b99f69-6ac7-44af-a1ef-54f893dedea1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'international', 'durporobash', '-1', 'events', 'opinion', 'entertainment', 'education', 'life-style', 'we-are', 'onnoalo', 'facebook', 'pachmisheli', 'sports', 'economy', 'roshalo', 'special-supplement', 'AskEditor', 'bangladesh', 'kishoralo', 'technology'}\n",
            "20\n"
          ]
        }
      ],
      "source": [
        "all_categories = set([sample['category'] for sample in data])\n",
        "print(all_categories)\n",
        "print(len(all_categories))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DX700LGygIYh"
      },
      "source": [
        "Sorting based on category count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlYg2zj2XMAS",
        "outputId": "b258860c-5457-47c9-90a1-029509e451a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'category': 'international', 'count': 5793}, {'category': 'durporobash', 'count': 1}, {'category': '-1', 'count': 27}, {'category': 'events', 'count': 2}, {'category': 'opinion', 'count': 2542}, {'category': 'entertainment', 'count': 5476}, {'category': 'education', 'count': 2509}, {'category': 'life-style', 'count': 1837}, {'category': 'we-are', 'count': 1149}, {'category': 'onnoalo', 'count': 442}, {'category': 'facebook', 'count': 10}, {'category': 'pachmisheli', 'count': 652}, {'category': 'sports', 'count': 9558}, {'category': 'economy', 'count': 2984}, {'category': 'roshalo', 'count': 551}, {'category': 'special-supplement', 'count': 152}, {'category': 'AskEditor', 'count': 1}, {'category': 'bangladesh', 'count': 43003}, {'category': 'kishoralo', 'count': 197}, {'category': 'technology', 'count': 3114}]\n",
            "[{'category': 'bangladesh', 'count': 43003}, {'category': 'sports', 'count': 9558}, {'category': 'international', 'count': 5793}, {'category': 'entertainment', 'count': 5476}, {'category': 'technology', 'count': 3114}, {'category': 'economy', 'count': 2984}, {'category': 'opinion', 'count': 2542}, {'category': 'education', 'count': 2509}, {'category': 'life-style', 'count': 1837}, {'category': 'we-are', 'count': 1149}, {'category': 'pachmisheli', 'count': 652}, {'category': 'roshalo', 'count': 551}, {'category': 'onnoalo', 'count': 442}, {'category': 'kishoralo', 'count': 197}, {'category': 'special-supplement', 'count': 152}, {'category': '-1', 'count': 27}, {'category': 'facebook', 'count': 10}, {'category': 'events', 'count': 2}, {'category': 'durporobash', 'count': 1}, {'category': 'AskEditor', 'count': 1}]\n"
          ]
        }
      ],
      "source": [
        "category_count_list = []\n",
        "count = 0\n",
        "for cat in all_categories:\n",
        "  count = 0\n",
        "  for row in data:\n",
        "    if row['category'] == cat:\n",
        "      count += 1\n",
        "  category_count_list.append({'category': cat, 'count': count})\n",
        "print(category_count_list)\n",
        "\n",
        "from operator import itemgetter\n",
        "sorted_cat_count_list = []\n",
        "# sorted_cat_count_list = sorted(category_count_list, key=lambda x: x.count, reverse=True)\n",
        "category_count_list.sort(key = itemgetter('count'), reverse=True)\n",
        "print(category_count_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x16W7C39p6Uc"
      },
      "source": [
        "Discard low count catagories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_M8jRkFdJN-",
        "outputId": "e1fe9542-3f8c-494c-c4c8-afac3921c290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['bangladesh', 'sports', 'international', 'entertainment', 'technology', 'economy', 'opinion', 'education', 'life-style', 'we-are']\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "selected_cats = []\n",
        "\n",
        "for p in category_count_list:\n",
        "    if p['count'] > 1000:\n",
        "        selected_cats.append(p['category'])\n",
        "print(selected_cats)\n",
        "print(len(selected_cats))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gsvlmxdsHK0"
      },
      "source": [
        "Prepare data X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeM7wizepzDf",
        "outputId": "77050719-0db1-4d45-e447-4a71c1373da5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "77965 77965\n"
          ]
        }
      ],
      "source": [
        "x_text = []\n",
        "y_label = []\n",
        "\n",
        "for row in data:\n",
        "    if row['category'] in selected_cats:\n",
        "        y_label.append(row['category'])\n",
        "        x_text.append(row['content'])\n",
        "print(len(x_text),len(y_label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in7FQnWsOyKM"
      },
      "source": [
        "Split data into Train & test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrf2WY8HbPaP"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_text,y_label, stratify=y_label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcI9JZzYNJ7A"
      },
      "source": [
        "Import neccessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWPB9W0Eb_BC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pGJ7qqVKcFxJ",
        "outputId": "a32bca6d-a59f-4b43-9b40-c7c40f329d98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.8.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2.9,>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.1.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (3.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.43.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (13.0.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (57.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.13.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (3.17.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (0.24.0)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 43.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (1.21.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (2.8.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (2.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.9,>=2.8.0->tensorflow-text) (3.10.0.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (4.11.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow<2.9,>=2.8.0->tensorflow-text) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, tensorflow-text\n",
            "Successfully installed tensorflow-text-2.8.1 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install tensorflow-text\n",
        "import tensorflow_text as text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir3qsOW3NQIW"
      },
      "source": [
        "import multi-bert preprocessor & encoder from tensorflow hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lm0KvKibcjmw"
      },
      "outputs": [],
      "source": [
        "bert_preprocess = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3')\n",
        "bert_encoder = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjUz_IiYNXeS"
      },
      "source": [
        "Build classifier model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxkfUIVDcSDQ"
      },
      "outputs": [],
      "source": [
        "# Bert layers\n",
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "preprocessed_text = bert_preprocess(text_input)\n",
        "outputs = bert_encoder(preprocessed_text)\n",
        "# Neural network layers\n",
        "net = tf.keras.layers.Dense(20, activation='relu')(outputs['pooled_output'])\n",
        "net = tf.keras.layers.Dropout(0.2)(net)\n",
        "# net = tf.keras.layers.Dense(32, activation='relu')(net)\n",
        "# net = tf.keras.layers.Dropout(0.2)(net)\n",
        "# net = tf.keras.layers.Dense(16,  activation='relu')(net)\n",
        "# net = tf.keras.layers.Dropout(0.1)(net)\n",
        "out = tf.keras.layers.Dense(10, activation='softmax', name=\"output\")(net)\n",
        "# Use inputs and outputs to construct a final model\n",
        "model = tf.keras.Model(inputs=[text_input], outputs = [out])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FiIc-KgZyEH"
      },
      "source": [
        "One hot encoding of Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbrwpptcdjt4"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "def make_ohe(y_label):\n",
        "  # Label Encode\n",
        "  encoder = LabelEncoder()\n",
        "  class_labels = encoder.fit_transform(y_label)\n",
        "  print(class_labels,len(class_labels),class_labels.shape)\n",
        "  print(set(class_labels))\n",
        "\n",
        "  #One hot Encode\n",
        "  encoder = OneHotEncoder(sparse=False)\n",
        "  class_labels = class_labels.reshape((class_labels.shape[0], 1))\n",
        "  y_ohe = encoder.fit_transform(class_labels)\n",
        "  print(y_ohe,y_ohe.shape)\n",
        "  return y_ohe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DMyozjsdlFh",
        "outputId": "9cd01878-5ec6-4539-96e2-442fc3c37f93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 7 0 3] 58473 (58473,)\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]] (58473, 10)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "y_train = make_ohe(y_train)\n",
        "print(type(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtmlD_cldnwI",
        "outputId": "cdfc79db-fe8b-4747-ece9-3f8eca802e62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 2 0 9] 19492 (19492,)\n",
            "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]] (19492, 10)\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "y_test = make_ohe(y_test)\n",
        "print(type(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfHWr-0TeQnX",
        "outputId": "f33c8a0b-3cac-4e64-b054-b760becddea3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "X_train = np.asarray(X_train)\n",
        "print(type(X_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL5v2NUuNo9g"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxptoc3VcWPT",
        "outputId": "fdcb69b6-db77-4902-b868-2bc9109bad72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1828/1828 [==============================] - ETA: 0s - loss: 1.1397 - accuracy: 0.6576\n",
            "Epoch 1: loss improved from inf to 1.13969, saving model to mbert_80k.h5\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1828/1828 [==============================] - 1320s 713ms/step - loss: 1.1397 - accuracy: 0.6576\n",
            "Epoch 2/10\n",
            "1828/1828 [==============================] - ETA: 0s - loss: 0.8658 - accuracy: 0.7390\n",
            "Epoch 2: loss improved from 1.13969 to 0.86581, saving model to mbert_80k.h5\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1828/1828 [==============================] - 1295s 708ms/step - loss: 0.8658 - accuracy: 0.7390\n",
            "Epoch 3/10\n",
            "1828/1828 [==============================] - ETA: 0s - loss: 0.7924 - accuracy: 0.7546\n",
            "Epoch 3: loss improved from 0.86581 to 0.79244, saving model to mbert_80k.h5\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1828/1828 [==============================] - 1294s 708ms/step - loss: 0.7924 - accuracy: 0.7546\n",
            "Epoch 4/10\n",
            "1828/1828 [==============================] - ETA: 0s - loss: 0.7525 - accuracy: 0.7618\n",
            "Epoch 4: loss improved from 0.79244 to 0.75252, saving model to mbert_80k.h5\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1828/1828 [==============================] - 1293s 707ms/step - loss: 0.7525 - accuracy: 0.7618\n",
            "Epoch 5/10\n",
            "1828/1828 [==============================] - ETA: 0s - loss: 0.7269 - accuracy: 0.7679\n",
            "Epoch 5: loss improved from 0.75252 to 0.72686, saving model to mbert_80k.h5\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1828/1828 [==============================] - 1296s 709ms/step - loss: 0.7269 - accuracy: 0.7679\n",
            "Epoch 6/10\n",
            "1828/1828 [==============================] - ETA: 0s - loss: 0.7100 - accuracy: 0.7728\n",
            "Epoch 6: loss improved from 0.72686 to 0.71001, saving model to mbert_80k.h5\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1828/1828 [==============================] - 1293s 707ms/step - loss: 0.7100 - accuracy: 0.7728\n",
            "Epoch 7/10\n",
            "1828/1828 [==============================] - ETA: 0s - loss: 0.6982 - accuracy: 0.7785\n",
            "Epoch 7: loss improved from 0.71001 to 0.69820, saving model to mbert_80k.h5\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1828/1828 [==============================] - 1292s 707ms/step - loss: 0.6982 - accuracy: 0.7785\n",
            "Epoch 8/10\n",
            "1828/1828 [==============================] - ETA: 0s - loss: 0.6858 - accuracy: 0.7836\n",
            "Epoch 8: loss improved from 0.69820 to 0.68581, saving model to mbert_80k.h5\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1828/1828 [==============================] - 1288s 705ms/step - loss: 0.6858 - accuracy: 0.7836\n",
            "Epoch 9/10\n",
            "1828/1828 [==============================] - ETA: 0s - loss: 0.6769 - accuracy: 0.7849\n",
            "Epoch 9: loss improved from 0.68581 to 0.67694, saving model to mbert_80k.h5\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1828/1828 [==============================] - 1288s 704ms/step - loss: 0.6769 - accuracy: 0.7849\n",
            "Epoch 10/10\n",
            "1828/1828 [==============================] - ETA: 0s - loss: 0.6688 - accuracy: 0.7883\n",
            "Epoch 10: loss improved from 0.67694 to 0.66875, saving model to mbert_80k.h5\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1828/1828 [==============================] - 1293s 707ms/step - loss: 0.6688 - accuracy: 0.7883\n"
          ]
        }
      ],
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('mbert_80k.h5', monitor='loss', save_best_only=True, verbose=1)\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=15, verbose=1)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "train_history = model.fit(X_train, y_train, epochs=10,callbacks=[checkpoint, earlystopping], batch_size = 32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4NqA-ls7yJV"
      },
      "source": [
        "Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97MRGFDh7g4A"
      },
      "outputs": [],
      "source": [
        "model.save(\"mbert_80k.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJgQfsQsMOBe"
      },
      "outputs": [],
      "source": [
        "# model = tf.keras.models.load_model(\"mbert_80k.h5\")\n",
        "saved_model = tf.keras.models.load_model(\"mbert_80k.h5\",custom_objects={'KerasLayer':hub.KerasLayer})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJIMjGC1R0sS"
      },
      "outputs": [],
      "source": [
        "model = saved_model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvcthngbe3TN"
      },
      "source": [
        "Train data accuracy evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vpbgj1JUeWu8",
        "outputId": "c669113c-dccd-4b41-961a-c59071356327"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6740204880885194\n"
          ]
        }
      ],
      "source": [
        "y_predicted_train = model.predict(X_train)\n",
        "y_out_train = []\n",
        "y_out_pred_train = []\n",
        "true_count = 0\n",
        "for i in range(len(y_predicted_train)):\n",
        "  y_out_train.append(np.argmax(y_train[i]))\n",
        "  y_out_pred_train.append(np.argmax(y_predicted_train[i]))\n",
        "  if (y_out_train[i] == y_out_pred_train[i]):\n",
        "    true_count += 1\n",
        "# print(np.shape(y_out),np.shape(y_label))\n",
        "\n",
        "accuracy = true_count/len(y_train)\n",
        "print(accuracy)\n",
        "# print(y_out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIPt-iFbQXhY"
      },
      "source": [
        "Test data accuracy evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGZVMIqHgKGj"
      },
      "outputs": [],
      "source": [
        "y_predicted = model.predict(X_test)\n",
        "y_out = []\n",
        "y_out_pred = []\n",
        "true_count = 0\n",
        "for i in range(len(y_predicted)):\n",
        "  y_out.append(np.argmax(y_test[i]))\n",
        "  y_out_pred.append(np.argmax(y_predicted[i]))\n",
        "  if (y_out[i] == y_out_pred[i]):\n",
        "    true_count += 1\n",
        "print(np.shape(y_out),np.shape(y_label))\n",
        "\n",
        "accuracy = true_count/len(y_test)\n",
        "print(accuracy)\n",
        "# print(y_out)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Bangla Newspaper Classification using multi-BERT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
